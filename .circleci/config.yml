---
version: 2.1

commands:
  ubuntu-install-pip3:
    description: "Install pip3 onto image"
    steps:
      - run:
          name: Get Python3 Version
          command: python3 --version
      - run:
          name: Update apt
          command: sudo apt update
      - run:
          name: Install pip3
          command: sudo apt install python3-pip
      - run:
          name: Get pip3 version
          command: pip3 --version

  ubuntu-install-aws:
    description: "Install AWS on Ubuntu"
    steps:
      - run:
          name: Update Apt
          command: |
            # Update Apt
            sudo apt update
      - run:
          name: Install AWS and dependencies
          command: |
            # install the dependencies needed for your playbook
            sudo apt -y install awscli

  destroy-environment-on-fail:
    description: Destroy Cloudformation stacks given a Workflow ID
    parameters:
      workflow_id:
        type: string      
    steps:
      - run:
          name: Destroy environments "${CIRCLE_WORKFLOW_ID:0:7}"
          when: on_fail
          command: |
            echo "Destroying environment: << parameters.workflow_id >> "
            # Your code goes here
            aws cloudformation delete-stack --stack-name webscraper-servers-<< parameters.workflow_id >>

jobs:
  lint:
    docker:
      - image: cimg/base:stable-20.04
    steps:
      - checkout
      - ubuntu-install-pip3
      - run:
          name: Install all python linting tools for project
          command: make install-python-lint
      - run:
          name: Install hadolint for docker linting
          command: sudo make install-hadolint
      - run:
          name: Lint Python Unit Tests
          command: make lint-python
      - run:
          name: Lint Dockerfile for scrape-api
          command: make lint-docker
      #- run:
      #    name: Lint AWS CloudFormation Templates
      #    command: make lint-aws-cf
  
  build-and-test:
    docker:
      - image: cimg/base:stable-20.04
    steps:
      - checkout
      - setup_remote_docker:
          docker_layer_caching: true
          version: 20.10.11
      - ubuntu-install-pip3
      - run:
          name: Install all Python Application Libraries
          command: make install-scrape-api
      - run:
          name: Install all Python Unit Test Libraries
          command: make install-unit-test
      - run:
          name: Run Python Application
          command: |
            cd src/scrape-api/
            ./run_docker.sh
            cd ..
            cd ..
      - run:
          name: Python Unit Tests
          command: |
            sleep 15
            ssh remote-docker \ curl --fail 127.0.0.1:5001/
            ssh remote-docker \ curl --fail 127.0.0.1:5001/config-management
            ssh remote-docker \ curl --fail 127.0.0.1:5001/containers
            ssh remote-docker \ curl --fail 127.0.0.1:5001/health

  upload-docker-image:
    docker:
      - image: cimg/base:stable-20.04
    steps:
      - checkout
      - setup_remote_docker:
          docker_layer_caching: true
          version: 20.10.11
      - ubuntu-install-pip3
      - run:
          name: Upload Docker Image
          command: |
            cd src/scrape-api/
            ./run_docker.sh
            ./upload_docker.sh
  
  deploy-infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: 
          name: Install tar and gzip
          command: |
            yum install -y tar gzip
      - run: 
          name: Change into CloudFormation directory
          command: |
            cd .aws-cf-iac
      - run:
          name: Store Old Workflow ID in advance
          command: |
            aws cloudformation list-exports \
              --query "Exports[?Name==\`WorkflowID\`].Value" \
              --no-paginate --output text | cut -f 2 -d '-' > ~/OLD_WORKFLOW_ID.txt
            cat ~/OLD_WORKFLOW_ID.txt
      - run:
          name: Ensure back-end infrastructure exists
          command: |
            cd .aws-cf-iac
            ./bash-create.sh webscraper-servers-${CIRCLE_WORKFLOW_ID:0:7} aws-servers.yml ${CIRCLE_WORKFLOW_ID:0:7}
      - run:
          name: Add back-end ip to ansible inventory
          command: |
            echo "[web-servers]" 2>&1 | tee -a ~/inventory.txt
            aws ec2 describe-instances \
              --query 'Reservations[*].Instances[*].PublicIpAddress' \
              --filters "Name=tag:Name,Values=webscraper-cluster-webserver-ec2-${CIRCLE_WORKFLOW_ID:0:7}" \
              --output text 2>&1 | tee -a  ~/inventory.txt
      - run:
          name: Check Text Files
          command: |
            cd ~/
            cat inventory.txt
            cat OLD_WORKFLOW_ID.txt
            echo "Contents Listed"
      - persist_to_workspace:
          root: ~/
          paths:
            - inventory.txt
            - OLD_WORKFLOW_ID.txt
      - destroy-environment-on-fail:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
  
  # TODO
  configure-infrastructure:
    docker:
      - image: cimg/base:stable-20.04
    steps:
      - checkout
      - ubuntu-install-pip3
      - ubuntu-install-aws
      - add_ssh_keys:
          fingerprints:
            71:99:cb:c3:f9:9c:39:03:cf:fb:87:29:29:e1:f9:a9
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: "Move Workspace Over"
          command: mv /tmp/workspace/inventory.txt .ansible/.
      - run:
          name: Update Apt
          command: |
            # Update Apt
            sudo apt update
      - run:
          name: Install dependencies
          command: |
            # install the dependencies needed for your playbook
            sudo apt -y install tar gzip ansible awscli
      - run:
          name: Configure server
          command: |
            cd .ansible/
            ansible-playbook -i inventory.txt configure-server.yml
      - destroy-environment-on-fail:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
  
  # TODO
  smoke-test:
    docker:
      - image: cimg/base:stable-20.04
    steps:
      - checkout
      - ubuntu-install-pip3
      - ubuntu-install-aws
      - destroy-environment-on-fail:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
  
  blue-green-switch:
    docker:
      - image: cimg/base:stable-20.04
    steps:
      - checkout
      - ubuntu-install-pip3
      - ubuntu-install-aws
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: "Move Workspace Over"
          command: mv /tmp/workspace/OLD_WORKFLOW_ID.txt .aws-cf-iac/.
      - run:
          name: Update ALB and delete old Infra
          command: |
            cd .aws-cf-iac
            echo "Pointing New albs to ${CIRCLE_WORKFLOW_ID:0:7}"
            ./bash-create.sh webscraper-alb aws-alb.yml ${CIRCLE_WORKFLOW_ID:0:7}

            export OLD_WORKFLOW_ID=$(cat OLD_WORKFLOW_ID.txt)
            echo "Deleting old Servers at ${OLD_WORKFLOW_ID}"
            ./bash-delete.sh webscraper-servers-${OLD_WORKFLOW_ID}

workflows:
  blue-green-pipeline:
    jobs:
      - lint
      - build-and-test:
          requires:
            - lint
      - upload-docker-image:
          requires:
            - build-and-test
          filters:
            branches:
              only:
                - main
      - deploy-infrastructure:
          requires:
            - upload-docker-image
      - configure-infrastructure:
          requires:
            - deploy-infrastructure
      - smoke-test:
          requires:
            - configure-infrastructure
      - blue-green-switch:
          requires:
            - smoke-test
...